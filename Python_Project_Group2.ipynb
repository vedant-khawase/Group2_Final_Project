{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "am0u_Mezzf8m"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'seaborn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mio\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import requests\n",
        "import io\n",
        "\n",
        "%reload_ext google.colab.data_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS4eq5o30uFH",
        "outputId": "b602112f-f807-44b7-d95a-8ff34b9a0118"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-54c0961aeb5e>:12: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  confirmed_cases_global = confirmed_cases_df.groupby(['Country/Region']).sum().reset_index()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Country/Region  Lat_confirmed  Long_confirmed  1/22/20_confirmed  \\\n",
            "0             Afghanistan      33.939110       67.709953                  0   \n",
            "1                 Albania      41.153300       20.168300                  0   \n",
            "2                 Algeria      28.033900        1.659600                  0   \n",
            "3                 Andorra      42.506300        1.521800                  0   \n",
            "4                  Angola     -11.202700       17.873900                  0   \n",
            "..                    ...            ...             ...                ...   \n",
            "196    West Bank and Gaza      31.952200       35.233200                  0   \n",
            "197  Winter Olympics 2022      39.904200      116.407400                  0   \n",
            "198                 Yemen      15.552727       48.516388                  0   \n",
            "199                Zambia     -13.133897       27.849332                  0   \n",
            "200              Zimbabwe     -19.015438       29.154857                  0   \n",
            "\n",
            "     1/23/20_confirmed  1/24/20_confirmed  1/25/20_confirmed  \\\n",
            "0                    0                  0                  0   \n",
            "1                    0                  0                  0   \n",
            "2                    0                  0                  0   \n",
            "3                    0                  0                  0   \n",
            "4                    0                  0                  0   \n",
            "..                 ...                ...                ...   \n",
            "196                  0                  0                  0   \n",
            "197                  0                  0                  0   \n",
            "198                  0                  0                  0   \n",
            "199                  0                  0                  0   \n",
            "200                  0                  0                  0   \n",
            "\n",
            "     1/26/20_confirmed  1/27/20_confirmed  1/28/20_confirmed  ...  \\\n",
            "0                    0                  0                  0  ...   \n",
            "1                    0                  0                  0  ...   \n",
            "2                    0                  0                  0  ...   \n",
            "3                    0                  0                  0  ...   \n",
            "4                    0                  0                  0  ...   \n",
            "..                 ...                ...                ...  ...   \n",
            "196                  0                  0                  0  ...   \n",
            "197                  0                  0                  0  ...   \n",
            "198                  0                  0                  0  ...   \n",
            "199                  0                  0                  0  ...   \n",
            "200                  0                  0                  0  ...   \n",
            "\n",
            "     2/28/23_deaths  3/1/23_deaths  3/2/23_deaths  3/3/23_deaths  \\\n",
            "0              7896           7896           7896           7896   \n",
            "1              3598           3598           3598           3598   \n",
            "2              6881           6881           6881           6881   \n",
            "3               165            165            165            165   \n",
            "4              1933           1933           1933           1933   \n",
            "..              ...            ...            ...            ...   \n",
            "196            5708           5708           5708           5708   \n",
            "197               0              0              0              0   \n",
            "198            2159           2159           2159           2159   \n",
            "199            4057           4057           4057           4057   \n",
            "200            5663           5668           5668           5668   \n",
            "\n",
            "     3/4/23_deaths  3/5/23_deaths  3/6/23_deaths  3/7/23_deaths  \\\n",
            "0             7896           7896           7896           7896   \n",
            "1             3598           3598           3598           3598   \n",
            "2             6881           6881           6881           6881   \n",
            "3              165            165            165            165   \n",
            "4             1933           1933           1933           1933   \n",
            "..             ...            ...            ...            ...   \n",
            "196           5708           5708           5708           5708   \n",
            "197              0              0              0              0   \n",
            "198           2159           2159           2159           2159   \n",
            "199           4057           4057           4057           4057   \n",
            "200           5668           5668           5668           5668   \n",
            "\n",
            "     3/8/23_deaths  3/9/23_deaths  \n",
            "0             7896           7896  \n",
            "1             3598           3598  \n",
            "2             6881           6881  \n",
            "3              165            165  \n",
            "4             1933           1933  \n",
            "..             ...            ...  \n",
            "196           5708           5708  \n",
            "197              0              0  \n",
            "198           2159           2159  \n",
            "199           4057           4057  \n",
            "200           5671           5671  \n",
            "\n",
            "[201 rows x 2291 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-54c0961aeb5e>:13: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  deaths_global = deaths_df.groupby(['Country/Region']).sum().reset_index()\n"
          ]
        }
      ],
      "source": [
        "#Reading the csv file to get the confirmed cases\n",
        "confirmed_cases_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"\n",
        "\n",
        "#Reading the csv file to get the total deaths\n",
        "deaths_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\"\n",
        "\n",
        "#Storing the Data into dataframe\n",
        "confirmed_cases_df = pd.read_csv(confirmed_cases_url)\n",
        "deaths_df = pd.read_csv(deaths_url)\n",
        "\n",
        "#aggregating and suming both data frames \n",
        "confirmed_cases_global = confirmed_cases_df.groupby(['Country/Region']).sum().reset_index()\n",
        "deaths_global = deaths_df.groupby(['Country/Region']).sum().reset_index()\n",
        "global_data = pd.merge(confirmed_cases_global, deaths_global, on='Country/Region', suffixes=('_confirmed', '_deaths'))\n",
        "print(global_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#research stock for industries (Overall American, overall Candian, Travel, Real Estate, Precious metals (Gold, Silver, Platinum and so on)) from AlphaVantage API\n",
        "overall_us_stock = 'SPY' # Overall American Market\n",
        "overall_ca_stock = 'XIU.TO' # Overall Canadian Market\n",
        "travel_stock = 'EXPE' # Travel sector (Expedia)\n",
        "real_estate_stock = 'VNQ' # The Real Estate sector (Vanguard Real Estate ETF)\n",
        "precious_metals_stock = 'GLD' # Precious metals (Gold ETF)\n",
        "api_key = 'QJCYHOCEUMEEI17F'\n",
        "base_url = 'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED'\n",
        "interval = 'daily'\n",
        "outputsize = 'compact'\n",
        "overall_us_stock_url = f\"{base_url}&symbol={overall_us_stock}&apikey={api_key}&interval={interval}&outputsize={outputsize}\"\n",
        "overall_ca_stock_url = f\"{base_url}&symbol={overall_ca_stock}&apikey={api_key}&interval={interval}&outputsize={outputsize}\"\n",
        "travel_stock_url = f\"{base_url}&symbol={travel_stock}&apikey={api_key}&interval={interval}&outputsize={outputsize}\"\n",
        "real_estate_stock_url = f\"{base_url}&symbol={real_estate_stock}&apikey={api_key}&interval={interval}&outputsize={outputsize}\"\n",
        "precious_metals_stock_url = f\"{base_url}&symbol={precious_metals_stock}&apikey={api_key}&interval={interval}&outputsize={outputsize}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get response for overall us stock from API\n",
        "overall_us_response = requests.get(overall_us_stock_url)\n",
        "SPY_data = pd.DataFrame.from_dict(overall_us_response.json()['Time Series (Daily)'], orient='index').reset_index()\n",
        "SPY_data['Date'] = pd.to_datetime(SPY_data.index)\n",
        "SPY_data = SPY_data[['Date', '2. high', '3. low']]\n",
        "SPY_data.columns = ['Date', 'SPY_High', 'SPY_Low']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get response for overall canada stock from API\n",
        "overall_ca_response = requests.get(overall_ca_stock_url)\n",
        "XIU_data = pd.DataFrame.from_dict(overall_ca_response.json()['Time Series (Daily)'], orient='index').reset_index()\n",
        "XIU_data['Date'] = pd.to_datetime(XIU_data.index)\n",
        "XIU_data = XIU_data[['Date', '2. high', '3. low']]\n",
        "XIU_data.columns = ['Date', 'XIU_High', 'XIU_Low']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get response for travel stock for Expedia from API\n",
        "travel_response = requests.get(travel_stock_url)\n",
        "EXPE_data = pd.DataFrame.from_dict(travel_response.json()['Time Series (Daily)'], orient='index').reset_index()\n",
        "EXPE_data['Date'] = pd.to_datetime(EXPE_data.index)\n",
        "EXPE_data = EXPE_data[['Date', '2. high', '3. low']]\n",
        "EXPE_data.columns = ['Date', 'EXPE_High', 'EXPE_Low']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get response for Vanguard Real Estate stock  from API\n",
        "real_estate_response = requests.get(real_estate_stock_url)\n",
        "VNQ_data = pd.DataFrame.from_dict(real_estate_response.json()['Time Series (Daily)'], orient='index').reset_index()\n",
        "VNQ_data['Date'] = pd.to_datetime(VNQ_data.index)\n",
        "VNQ_data = VNQ_data[['Date', '2. high', '3. low']]\n",
        "VNQ_data.columns = ['Date', 'EXPE_High', 'EXPE_Low']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get response for precious metal such as gold stock  from API\n",
        "precious_metals_response = requests.get(precious_metals_stock_url)\n",
        "GOLD_data = pd.DataFrame.from_dict(precious_metals_response.json()['Time Series (Daily)'], orient='index').reset_index()\n",
        "GOLD_data['Date'] = pd.to_datetime(GOLD_data.index)\n",
        "GOLD_data = GOLD_data[['Date', '2. high', '3. low']]\n",
        "GOLD_data.columns = ['Date', 'EXPE_High', 'EXPE_Low']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# combined data for all API response\n",
        "combined_data = pd.concat([global_data,SPY_data, XIU_data, EXPE_data, VNQ_data, GOLD_data], axis=1)\n",
        "print(combined_data)\n",
        "combined_data.to_excel(\"output.xlsx\",sheet_name='Sheet_name_1') "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
